{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this file once per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpybaseball\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m statcast_batter, statcast_pitcher, playerid_lookup, pitching_stats_range, batting_stats_range, schedule_and_record, team_game_logs, pybaseball\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timedelta, datetime\n",
      "File \u001b[1;32mc:\\Users\\kesse\\Development\\MLB-Analytics\\MLBpy\\Lib\\site-packages\\pandas\\__init__.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _dependency \u001b[38;5;129;01min\u001b[39;00m _hard_dependencies:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_dependency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     29\u001b[0m         _missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kesse\\Development\\MLB-Analytics\\MLBpy\\Lib\\site-packages\\pytz\\__init__.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytz\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AmbiguousTimeError\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytz\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidTimeError\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytz\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NonExistentTimeError\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1186\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ======================================== GAME PKs ================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pybaseball import statcast_batter, statcast_pitcher, playerid_lookup, pitching_stats_range, batting_stats_range, schedule_and_record, team_game_logs, pybaseball\n",
    "from datetime import timedelta, datetime\n",
    "import statsapi\n",
    "import pprint\n",
    "\n",
    "today = datetime.now()\n",
    "end_date = today.strftime('%Y-%m-%d')\n",
    "end_date = '2024-05-24'\n",
    "\n",
    "season = today.year\n",
    "\n",
    "\n",
    "def get_game_pks():\n",
    "    \n",
    "    desired_seasons = [2021, 2022, 2023, 2024] # Add Desired Seasons Here\n",
    "\n",
    "    data_fields = ['game_date', 'game_id', 'away_name', 'away_id', 'home_name', 'home_id']\n",
    "\n",
    "    ids_data = []\n",
    "\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "    for year in desired_seasons:\n",
    "\n",
    "        if desired_seasons.index(year) < len(desired_seasons)-1:\n",
    "            schedule = statsapi.schedule(start_date=f'{year}-01-01', end_date=f'{year}-12-31')\n",
    "\n",
    "            for game in schedule:\n",
    "                row = {field: game[field] for field in data_fields}\n",
    "                ids_data.append(row)\n",
    "\n",
    "            ids = pd.DataFrame(ids_data, columns=data_fields)\n",
    "        else:\n",
    "            schedule = statsapi.schedule(start_date=f'{year}-01-01', end_date=today)\n",
    "\n",
    "            for game in schedule:\n",
    "                row = {field: game[field] for field in data_fields}\n",
    "                ids_data.append(row)\n",
    "\n",
    "            ids = pd.DataFrame(ids_data, columns=data_fields)\n",
    "\n",
    "    ids.to_csv('game_pks.csv')\n",
    "\n",
    "get_game_pks() \n",
    "\n",
    "print('\\n\\nGame PKs updated.\\nNow creating Player IDs.\\n')\n",
    "\n",
    "# =========================================== PLAYER IDs ===================================================\n",
    "\n",
    "import pandas as pd\n",
    "from statsapi import player_stats\n",
    "from pybaseball import playerid_lookup, batting_stats_range, pitching_stats_range, playerid_reverse_lookup\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "start_date = '2021-01-01'\n",
    "start_season = 2021\n",
    "\n",
    "today = datetime.now()\n",
    "end_date = today.strftime('%Y-%m-%d')\n",
    "\n",
    "season = today.year\n",
    "\n",
    "batting = batting_stats_range(start_date, end_date)\n",
    "pitching = pitching_stats_range(start_date, end_date)\n",
    "\n",
    "batter_ids = batting[['Name', 'Tm', 'mlbID']]\n",
    "# Add an empty column 'key_bbref' initialized with None\n",
    "batter_ids['key_bbref'] = None\n",
    "\n",
    "# Loop through each player ID and fetch their bbref ID\n",
    "for idx, mlb_id in batter_ids.iterrows():\n",
    "\n",
    "    try:\n",
    "        # Fetch the data using the player ID\n",
    "        batterdata = playerid_reverse_lookup([mlb_id['mlbID']], key_type='mlbam')\n",
    "        if not batterdata.empty:\n",
    "            bbref = batterdata.at[0, 'key_bbref']  # Extract the bbref ID from the returned DataFrame\n",
    "            batter_ids.at[idx, 'key_bbref'] = bbref  # Assign the bbref ID to the respective row\n",
    "        else:\n",
    "                print(f\"No BBref ID found for mlbID: {mlb_id['mlbID']}, {mlb_id['Name']} (Batter)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing mlbID: {mlb_id['mlbID']}, Error: {e}\")\n",
    "\n",
    "\n",
    "# Ensure mlbID is converted to integers\n",
    "pitching['mlbID'] = pitching['mlbID'].astype(int)\n",
    "\n",
    "# Add an empty column 'key_bbref' initialized with None\n",
    "pitcher_ids = pitching[['Name', 'Tm', 'mlbID']].copy()\n",
    "pitcher_ids['key_bbref'] = None\n",
    "\n",
    "# Loop through each player ID and fetch their bbref ID\n",
    "for idx, row in pitcher_ids.iterrows():\n",
    "    mlb_id = row['mlbID']\n",
    "    \n",
    "    try:\n",
    "        # Fetch the data using the player ID\n",
    "        pitcherdata = playerid_reverse_lookup([mlb_id], key_type='mlbam')\n",
    "        \n",
    "        if not pitcherdata.empty:\n",
    "            bbref = pitcherdata.iloc[0]['key_bbref']  # Extract the bbref ID from the returned DataFrame\n",
    "            pitcher_ids.at[idx, 'key_bbref'] = bbref  # Assign the bbref ID to the respective row\n",
    "        else:\n",
    "            print(f\"No BBref ID found for mlbID: {mlb_id}, {row['Name']} (Pitcher)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing mlbID: {mlb_id}, Error: {e}\")\n",
    "\n",
    "batter_ids.to_csv('batter_ids.csv')\n",
    "pitcher_ids.to_csv('pitcher_ids.csv')\n",
    "\n",
    "print('\\n\\nPlayer IDs updated.\\nNow creating gamelogs.\\n')\n",
    "\n",
    "# ========================================= GAME LOGS ===============================================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pybaseball import playerid_reverse_lookup\n",
    "\n",
    "# Load game_pks.csv to get team names and IDs\n",
    "game_pks_df = pd.read_csv('game_pks.csv')\n",
    "\n",
    "# Mapping of team 3-digit IDs to oddshark 5-digit IDs \n",
    "team_to_oddshark_id = {\n",
    "    120: 27017, 146: 27022, 139: 27003, 144: 27009, 140: 27002, 117: 27023,\n",
    "    135: 26996, 143: 26995, 110: 27008, 136: 27011, 121: 27014, 109: 27007,\n",
    "    108: 26998, 133: 27016, 141: 27010, 114: 27014, 138: 27019, 142: 27005,\n",
    "    116: 26999, 147: 27001, 137: 26997, 118: 27006, 145: 27018, 115: 27004,\n",
    "    111: 27021, 119: 27015, 112: 27020, 158: 27012, 113: 27000, 134: 27013\n",
    "}\n",
    "\n",
    "errors = []\n",
    "\n",
    "def get_game_data(gamepk):\n",
    "    url = f\"https://statsapi.mlb.com/api/v1.1/game/{gamepk}/feed/live\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def get_bbref_id(mlbam_id):\n",
    "    try:\n",
    "        lookup_df = playerid_reverse_lookup([mlbam_id], key_type='mlbam')\n",
    "        bbref_id = lookup_df.loc[lookup_df['key_mlbam'] == mlbam_id, 'key_bbref'].values[0]\n",
    "        return bbref_id\n",
    "    except IndexError:\n",
    "        return 'unknown'\n",
    "\n",
    "def extract_starting_lineup(game_data, team_side):\n",
    "    lineup = {}\n",
    "    team = game_data['liveData']['boxscore']['teams'][team_side]['players']\n",
    "    \n",
    "    for player_id, player_info in team.items():\n",
    "        try:\n",
    "            if 'battingOrder' in player_info and int(player_info['battingOrder']) % 100 == 0:\n",
    "                order = int(player_info['battingOrder']) // 100\n",
    "                mlbam_id = player_info['person']['id']\n",
    "                bbref_id = get_bbref_id(mlbam_id)\n",
    "                lineup[order] = {\n",
    "                    'name': player_info['person']['fullName'],\n",
    "                    'mlbam_id': mlbam_id,\n",
    "                    'bbref_id': bbref_id\n",
    "                }\n",
    "        except Exception as e:\n",
    "            errors.append((gamepk, f\"Error processing player {player_id} in {team_side} lineup: {str(e)}\"))\n",
    "    \n",
    "    # Ensure lineup is filled and sorted by batting order\n",
    "    return [lineup.get(i, {'name': '', 'mlbam_id': '', 'bbref_id': ''}) for i in range(1, 10)]\n",
    "\n",
    "def get_pitchers(game_data, team_side):\n",
    "    team = game_data['liveData']['boxscore']['teams'][team_side]\n",
    "    pitchers = []\n",
    "    for idx, pitcher_id in enumerate(team['pitchers']):\n",
    "        try:\n",
    "            pitcher = team['players'][f'ID{pitcher_id}']\n",
    "            mlbam_id = pitcher['person']['id']\n",
    "            bbref_id = get_bbref_id(mlbam_id)\n",
    "            pitchers.append({\n",
    "                'name': pitcher['person']['fullName'],\n",
    "                'mlbam_id': mlbam_id,\n",
    "                'bbref_id': bbref_id,\n",
    "                'order': idx + 1\n",
    "            })\n",
    "        except Exception as e:\n",
    "            errors.append((gamepk, f\"Error processing pitcher {pitcher_id} in {team_side} team: {str(e)}\"))\n",
    "    return pitchers\n",
    "\n",
    "def get_bullpen(game_data, team_side):\n",
    "    team = game_data['liveData']['boxscore']['teams'][team_side]\n",
    "    bullpen = []\n",
    "    if team['pitchers']:  # Game already played\n",
    "        for pitcher_id in team['bullpen'] + team['pitchers'][1:]:\n",
    "            try:\n",
    "                pitcher = team['players'][f'ID{pitcher_id}']\n",
    "                mlbam_id = pitcher['person']['id']\n",
    "                bbref_id = get_bbref_id(mlbam_id)\n",
    "                bullpen.append({\n",
    "                    'name': pitcher['person']['fullName'],\n",
    "                    'mlbam_id': mlbam_id,\n",
    "                    'bbref_id': bbref_id\n",
    "                })\n",
    "            except Exception as e:\n",
    "                errors.append((gamepk, f\"Error processing bullpen pitcher {pitcher_id} in {team_side} team: {str(e)}\"))\n",
    "    else:  # Game not yet played\n",
    "        for pitcher_id in team['bullpen']:\n",
    "            try:\n",
    "                pitcher = team['players'][f'ID{pitcher_id}']\n",
    "                mlbam_id = pitcher['person']['id']\n",
    "                bbref_id = get_bbref_id(mlbam_id)\n",
    "                bullpen.append({\n",
    "                    'name': pitcher['person']['fullName'],\n",
    "                    'mlbam_id': mlbam_id,\n",
    "                    'bbref_id': bbref_id\n",
    "                })\n",
    "            except Exception as e:\n",
    "                errors.append((gamepk, f\"Error processing bullpen pitcher {pitcher_id} in {team_side} team: {str(e)}\"))\n",
    "    return bullpen\n",
    "\n",
    "def create_game_dataframe(gamepk):\n",
    "    game_data = get_game_data(gamepk)\n",
    "    \n",
    "    try:\n",
    "        home_lineup = extract_starting_lineup(game_data, 'home')\n",
    "        away_lineup = extract_starting_lineup(game_data, 'away')\n",
    "        home_bullpen = get_bullpen(game_data, 'home')\n",
    "        away_bullpen = get_bullpen(game_data, 'away')\n",
    "    except Exception as e:\n",
    "        errors.append((gamepk, f\"Error extracting lineups: {str(e)}\"))\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        home_pitchers = get_pitchers(game_data, 'home')\n",
    "        away_pitchers = get_pitchers(game_data, 'away')\n",
    "    except Exception as e:\n",
    "        errors.append((gamepk, f\"Error extracting pitchers: {str(e)}\"))\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get additional game information\n",
    "    game_info = game_pks_df[game_pks_df['game_id'] == gamepk].iloc[0]\n",
    "    \n",
    "    try:\n",
    "        game_date = game_info['game_date']\n",
    "    except KeyError:\n",
    "        game_date = 'unknown'\n",
    "        errors.append((gamepk, \"Error getting game date\"))\n",
    "    \n",
    "    try:\n",
    "        runs_home = game_data['liveData']['linescore']['teams']['home']['runs']\n",
    "    except KeyError:\n",
    "        runs_home = 0\n",
    "        errors.append((gamepk, \"Error getting home runs\"))\n",
    "    \n",
    "    try:\n",
    "        runs_away = game_data['liveData']['linescore']['teams']['away']['runs']\n",
    "    except KeyError:\n",
    "        runs_away = 0\n",
    "        errors.append((gamepk, \"Error getting away runs\"))\n",
    "    \n",
    "    runs_total = runs_home + runs_away\n",
    "    \n",
    "    # Get team information from game_pks.csv\n",
    "    home_id = game_info['home_id']\n",
    "    away_id = game_info['away_id']\n",
    "    home_name = game_info['home_name']\n",
    "    away_name = game_info['away_name']\n",
    "    \n",
    "    # Check for invalid team IDs\n",
    "    if home_id not in team_to_oddshark_id or away_id not in team_to_oddshark_id:\n",
    "        print(f\"Invalid team IDs - {home_name} {home_id} vs {away_name} {away_id}\")\n",
    "    \n",
    "    home_oddshark_id = team_to_oddshark_id.get(home_id, 'unknown')\n",
    "    away_oddshark_id = team_to_oddshark_id.get(away_id, 'unknown')\n",
    "    \n",
    "    game_record = {\n",
    "        'game_id': gamepk, 'game_date': game_date, 'runs_home': runs_home, 'runs_away': runs_away, 'runs_total': runs_total,\n",
    "        'home_id': home_id, 'home_name': home_name, 'away_id': away_id, 'away_name': away_name,\n",
    "        'home_oddshark_id': home_oddshark_id, 'away_oddshark_id': away_oddshark_id\n",
    "    }\n",
    "\n",
    "    for i, player in enumerate(away_lineup, start=1):\n",
    "        game_record[f'Away_Batter{i}_Name'] = player['name']\n",
    "        game_record[f'Away_Batter{i}_ID'] = player['mlbam_id']\n",
    "        game_record[f'Away_Batter{i}_bbrefID'] = player['bbref_id']\n",
    "        \n",
    "    for i, player in enumerate(home_lineup, start=1):\n",
    "        game_record[f'Home_Batter{i}_Name'] = player['name']\n",
    "        game_record[f'Home_Batter{i}_ID'] = player['mlbam_id']\n",
    "        game_record[f'Home_Batter{i}_bbrefID'] = player['bbref_id']\n",
    "    \n",
    "    # Add starting pitchers\n",
    "    if home_pitchers:\n",
    "        game_record['Home_SP_Name'] = home_pitchers[0]['name']\n",
    "        game_record['Home_SP_ID'] = home_pitchers[0]['mlbam_id']\n",
    "        game_record['Home_SP_bbrefID'] = home_pitchers[0]['bbref_id']\n",
    "    \n",
    "    if away_pitchers:\n",
    "        game_record['Away_SP_Name'] = away_pitchers[0]['name']\n",
    "        game_record['Away_SP_ID'] = away_pitchers[0]['mlbam_id']\n",
    "        game_record['Away_SP_bbrefID'] = away_pitchers[0]['bbref_id']\n",
    "    \n",
    "    # Add bullpen pitchers\n",
    "    for i, pitcher in enumerate(home_bullpen, start=1):\n",
    "        game_record[f'Home_bullpen_{i}_Name'] = pitcher['name']\n",
    "        game_record[f'Home_bullpen_{i}_ID'] = pitcher['mlbam_id']\n",
    "        game_record[f'Home_bullpen_{i}_bbrefID'] = pitcher['bbref_id']\n",
    "    \n",
    "    for i, pitcher in enumerate(away_bullpen, start=1):\n",
    "        game_record[f'Away_bullpen_{i}_Name'] = pitcher['name']\n",
    "        game_record[f'Away_bullpen_{i}_ID'] = pitcher['mlbam_id']\n",
    "        game_record[f'Away_bullpen_{i}_bbrefID'] = pitcher['bbref_id']\n",
    "\n",
    "\n",
    "    # Add remaining pitchers\n",
    "    for i, pitcher in enumerate(home_pitchers[1:], start=2):\n",
    "        game_record[f'Home_P_{i}_Name'] = pitcher['name']\n",
    "        game_record[f'Home_P_{i}_ID'] = pitcher['mlbam_id']\n",
    "        game_record[f'Home_P_{i}_bbrefID'] = pitcher['bbref_id']\n",
    "    \n",
    "    for i, pitcher in enumerate(away_pitchers[1:], start=2):\n",
    "        game_record[f'Away_P_{i}_Name'] = pitcher['name']\n",
    "        game_record[f'Away_P_{i}_ID'] = pitcher['mlbam_id']\n",
    "        game_record[f'Away_P_{i}_bbrefID'] = pitcher['bbref_id']\n",
    "    \n",
    "    return pd.DataFrame([game_record])\n",
    "\n",
    "def save_game_to_csv(gamepk):\n",
    "    game_df = create_game_dataframe(gamepk)\n",
    "    if not game_df.empty:\n",
    "        file_name = f'gamelogs/game_{gamepk}.csv'\n",
    "        game_df.to_csv(file_name, index=False)\n",
    "        #print(f\"Data exported to {file_name}\")\n",
    "    else:\n",
    "        print(f\"No data exported for game {gamepk}\")\n",
    "\n",
    "all_games = pd.read_csv('game_pks.csv').game_id\n",
    "\n",
    "\n",
    "gamepks = all_games.tail(100)\n",
    "count = 0\n",
    "for gamepk in gamepks:\n",
    "    save_game_to_csv(gamepk)\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        print(count)\n",
    "\n",
    "# Print collected errors\n",
    "if errors:\n",
    "    print(\"Errors encountered:\")\n",
    "    for error in errors:\n",
    "        print(error)\n",
    "else:\n",
    "    print(\"No errors encountered creating gamelogs.\")\n",
    "\n",
    "print('\\n\\nGame logs updated.\\nNow collecting odds data.\\n')\n",
    "\n",
    "# ==================================== ODDS DATA =======================================================================\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_over_under_runline(oddshark_id, game_date):\n",
    "    year = game_date.year\n",
    "    url = f\"https://www.oddsshark.com/stats/gamelog/baseball/mlb/{oddshark_id}?season={year}\"\n",
    "    \n",
    "    try:\n",
    "        tables = pd.read_html(url)\n",
    "        df = tables[0]\n",
    "    except Exception as e:\n",
    "        print(f\"BAD - error for team {oddshark_id} on date {game_date}: {e}\")\n",
    "        return 'unknown', None, None, None\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"BAD - No data in table for team {oddshark_id} on date {game_date}\")\n",
    "        return 'unknown', None, None, None\n",
    "    \n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%b %d, %Y')\n",
    "    matching_rows = df[df['Date'] == game_date]\n",
    "\n",
    "    if len(matching_rows) > 1:\n",
    "        print(f\"DOUBLEHEADER on {game_date}\")\n",
    "        return '', oddshark_id, year, game_date\n",
    "    \n",
    "    if matching_rows.empty:\n",
    "        print(f\"BAD - No matching date found for team {oddshark_id} on date {game_date}\")\n",
    "        return 'unknown', None, None, None\n",
    "    \n",
    "    over_under = matching_rows.iloc[0]['Total']\n",
    "    return over_under, None, None, None\n",
    "\n",
    "def update_gamelogs_with_over_under(game_pks_file, gamelogs_folder):\n",
    "    game_pks_df = pd.read_csv(game_pks_file)\n",
    "    game_pks = game_pks_df['game_id'].tail(50)  # Set the number of recent games to do\n",
    "    duplicates = []\n",
    "    \n",
    "    count = 0\n",
    "    for game_id in game_pks:\n",
    "        try:\n",
    "            gamelog_file = f'{gamelogs_folder}/game_{game_id}.csv'\n",
    "            gamelog_df = pd.read_csv(gamelog_file)\n",
    "            \n",
    "            home_oddshark_id = gamelog_df.loc[0, 'home_oddshark_id']\n",
    "            game_date_str = gamelog_df.loc[0, 'game_date']\n",
    "            game_date = datetime.strptime(game_date_str, '%Y-%m-%d')\n",
    "            \n",
    "            over_under_runline, duplicate_id, duplicate_year, duplicate_date = fetch_over_under_runline(home_oddshark_id, game_date)\n",
    "            \n",
    "            if duplicate_id:\n",
    "                duplicates.append((duplicate_id, duplicate_year, duplicate_date))\n",
    "                \n",
    "            gamelog_df['over_under_runline'] = over_under_runline\n",
    "             \n",
    "            gamelog_df.to_csv(gamelog_file, index=False)\n",
    "            print(f\"Updated {gamelog_file} with over/under runline.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating gamelog for game_id {game_id}: {e}\")\n",
    "\n",
    "        count+=1\n",
    "        if count % 100:\n",
    "            print(count)\n",
    "    \n",
    "    print(\"\\nGames with duplicate dates:\")\n",
    "    for dup in duplicates:\n",
    "        print(f\"Team Oddshark ID: {dup[0]}, Year: {dup[1]}, Date: {dup[2].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Update the paths as necessary\n",
    "game_pks_file = 'game_pks.csv'\n",
    "gamelogs_folder = 'gamelogs'\n",
    "\n",
    "# Run the update function\n",
    "update_gamelogs_with_over_under(game_pks_file, gamelogs_folder)\n",
    "\n",
    "print('\\n\\nOdds Data updated.\\nNow updating player stats.\\n')\n",
    "\n",
    "# ================================== PLAYER STATS ===================================================\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import re \n",
    "from dateutil import parser\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "from pybaseball import batting_stats_range, pitching_stats_range, playerid_reverse_lookup\n",
    "import statsapi\n",
    "import os\n",
    "\n",
    "def fetch_b_game_log(player_id, year):\n",
    "    # Construct the URL for the batter's game log for the given year\n",
    "    url = f'https://www.baseball-reference.com/players/gl.fcgi?id={player_id}&t=b&year={year}'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\" BAD - Failed to fetch data for batter {player_id} in {year}\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # Find the table containing the game logs\n",
    "    table = soup.find('table', {'id': 'batting_gamelogs'})\n",
    "    \n",
    "    # Check if the table is found\n",
    "    if table is None:\n",
    "        print(f\"No data found for batter {player_id} in {year} - OK\")\n",
    "        return None\n",
    "    \n",
    "    # Read the table into a pandas DataFrame\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    \n",
    "    # Remove rows where 'Rk' is not a number (header rows that repeat in the table)\n",
    "    df = df[pd.to_numeric(df['Rk'], errors='coerce').notnull()]\n",
    "    \n",
    "    # Add the year to the 'Date' column if the year is not already present\n",
    "    df['Date'] = df['Date'].apply(lambda x: f\"{x}, {year}\" if '(' not in x else x)\n",
    "    \n",
    "    # Extract the value from parentheses (if present) and assign it to a new column 'dbl'\n",
    "    df['dbl'] = df['Date'].str.extract(r'\\((\\d+)\\)').astype(float)\n",
    "    \n",
    "    # Add the year to the 'Date' column for doubleheader dates\n",
    "    df.loc[df['dbl'].notnull(), 'Date'] = df['Date'] + ', ' + str(year)\n",
    "    \n",
    "    # Format 'Date' to 'game_date' in YYYY-MM-DD format\n",
    "    df['game_date'] = pd.to_datetime(df['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fetch_p_game_log(player_id, year):\n",
    "    # Construct the URL for the pitcher's game log for the given year\n",
    "    url = f'https://www.baseball-reference.com/players/gl.fcgi?id={player_id}&t=p&year={year}'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\" BAD - Failed to fetch data for pitcher {player_id} in {year}\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # Find the table containing the game logs\n",
    "    table = soup.find('table', {'id': 'pitching_gamelogs'})\n",
    "    \n",
    "    # Check if the table is found\n",
    "    if table is None:\n",
    "        print(f\"No data found for pitcher {player_id} in {year} - OK\")\n",
    "        return None\n",
    "    \n",
    "    # Read the table into a pandas DataFrame\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    \n",
    "    # Remove rows where 'Rk' is not a number (header rows that repeat in the table)\n",
    "    df = df[pd.to_numeric(df['Rk'], errors='coerce').notnull()]\n",
    "    \n",
    "    # Add the year to the 'Date' column if the year is not already present\n",
    "    df['Date'] = df['Date'].apply(lambda x: f\"{x}, {year}\" if '(' not in x else x)\n",
    "    \n",
    "    # Extract the value from parentheses (if present) and assign it to a new column 'dbl'\n",
    "    df['dbl'] = df['Date'].str.extract(r'\\((\\d+)\\)').astype(float)\n",
    "    \n",
    "    # Add the year to the 'Date' column for doubleheader dates\n",
    "    df.loc[df['dbl'].notnull(), 'Date'] = df['Date'] + ', ' + str(year)\n",
    "    \n",
    "    # Format 'Date' to 'game_date' in YYYY-MM-DD format\n",
    "    df['game_date'] = pd.to_datetime(df['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to clean and parse dates\n",
    "def clean_date(date_str, year):\n",
    "    try:\n",
    "        # Replace invisible characters like U+00A0 with a space\n",
    "        date_str = date_str.replace('\\xa0', ' ')\n",
    "        # Remove any null characters and non-printable characters\n",
    "        date_str = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', date_str)\n",
    "        # Remove unwanted characters and extra text like \"(1)\" or \"susp\"\n",
    "        date_str = re.sub(r'\\(.*?\\)', '', date_str)  # Remove text inside parentheses\n",
    "        date_str = ''.join(char for char in date_str if char.isalnum() or char.isspace() or char == ',')\n",
    "        # Remove specific unwanted words like \"susp\"\n",
    "        date_str = date_str.replace('susp', '').strip()\n",
    "        # Parse the cleaned string to a date object\n",
    "        parsed_date = parser.parse(date_str)\n",
    "        # Force the year to be 2021\n",
    "        parsed_date = parsed_date.replace(year=year)\n",
    "        # Format the date to 'YYYY-MM-DD'\n",
    "        #print(parsed_date)\n",
    "        return parsed_date.strftime('%Y-%m-%d')\n",
    "    except Exception as e:\n",
    "        # Print the error for debugging purposes\n",
    "        print(f\"Error parsing date '{date_str}': {e}\")\n",
    "        # Handle any parsing errors by returning None\n",
    "        return None\n",
    "\n",
    "# Get today's date\n",
    "today = date.today()\n",
    "\n",
    "# Define end date\n",
    "end_date = today.strftime('%Y-%m-%d')\n",
    "\n",
    "def get_active_player_ids(game_data):\n",
    "    active_batters = set()  # Use a set to avoid duplicates\n",
    "    active_pitchers = set()  # Use a set to avoid duplicates\n",
    "    \n",
    "    for game in game_data:\n",
    "        game_id = game['game_id']\n",
    "        boxscore = statsapi.boxscore_data(game_id)\n",
    "        \n",
    "        for team_key in ['away', 'home']:\n",
    "            if team_key in boxscore:\n",
    "                team_data = boxscore[team_key]\n",
    "                if 'batters' in team_data:\n",
    "                    active_batters.update(team_data['batters'])\n",
    "                if 'pitchers' in team_data:\n",
    "                    active_pitchers.update(team_data['pitchers'])\n",
    "                    \n",
    "    return list(active_batters), list(active_pitchers)\n",
    "\n",
    "# Get recent games\n",
    "recent_games = statsapi.schedule(start_date=(today - timedelta(days=2)).strftime('%Y-%m-%d'), end_date=end_date)\n",
    "\n",
    "# Get active batters and pitchers\n",
    "active_batter_ids, active_pitcher_ids = get_active_player_ids(recent_games)\n",
    "\n",
    "# Use playerid_reverse_lookup to get bbref_id\n",
    "def get_bbref_ids(player_ids):\n",
    "    player_data = playerid_reverse_lookup(player_ids, key_type='mlbam')\n",
    "    return player_data[['key_mlbam', 'key_bbref']]\n",
    "\n",
    "# Get bbref IDs for active batters and pitchers\n",
    "active_batter_data = get_bbref_ids(active_batter_ids)\n",
    "active_pitcher_data = get_bbref_ids(active_pitcher_ids)\n",
    "\n",
    "# Save to CSV\n",
    "active_batter_data.to_csv('active_batter_ids.csv', index=False)\n",
    "active_pitcher_data.to_csv('active_pitcher_ids.csv', index=False)\n",
    "\n",
    "# Load active player IDs\n",
    "active_batter_ids = pd.read_csv('active_batter_ids.csv')['key_bbref']\n",
    "active_pitcher_ids = pd.read_csv('active_pitcher_ids.csv')['key_bbref']\n",
    "\n",
    "# Load game Pks\n",
    "game_pks = pd.read_csv('game_pks.csv')\n",
    "\n",
    "# Define the mapping from abbreviated team names to full team names\n",
    "team_id_mapping = {\n",
    "    'WSN': 120, 'MIA': 146, 'TBR': 139, 'ATL': 144, 'TEX': 140, 'HOU': 117,\n",
    "    'SD': 135, 'SDP': 135, 'PHI': 143, 'BAL': 110, 'SEA': 136, 'NYM': 121,\n",
    "    'ARI': 109, 'LAA': 108, 'OAK': 133, 'TOR': 141, 'CLE': 114, 'STL': 138,\n",
    "    'MIN': 142, 'DET': 116, 'NYY': 147, 'SFG': 137, 'KCR': 118, 'CWS': 145,\n",
    "    'CHW': 145, 'COL': 115, 'BOS': 111, 'LAD': 119, 'CHC': 112, 'MIL': 158,\n",
    "    'CIN': 113, 'PIT': 134\n",
    "}\n",
    "\n",
    "# Define the current year\n",
    "current_year = 2024\n",
    "\n",
    "# Function to process and save player data\n",
    "def process_player_data(player_ids, player_type='batter'):\n",
    "    fetch_game_log = fetch_b_game_log if player_type == 'batter' else fetch_p_game_log\n",
    "    \n",
    "    for id in player_ids:\n",
    "        if not id or pd.isna(id):\n",
    "            continue\n",
    "\n",
    "         # Load the existing player data if it exists\n",
    "        player_file_path = f'{player_type}s/{id}_{player_type}ing.csv'\n",
    "        if player_type == 'batter':\n",
    "            player_file_path = f'batters/{id}_batting.csv'\n",
    "        elif player_type == 'pitcher':\n",
    "            player_file_path = f'pitchers/{id}_pitching.csv'\n",
    "            \n",
    "        if os.path.exists(player_file_path):\n",
    "            player_df = pd.read_csv(player_file_path)\n",
    "        else:\n",
    "            player_df = pd.DataFrame()\n",
    "\n",
    "        # Fetch data for the current year\n",
    "        new_data_df = fetch_game_log(id, current_year)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        # Check if the fetched dataframe is None or empty\n",
    "        if new_data_df is None or new_data_df.empty:\n",
    "            continue  # Skip if no data available\n",
    "\n",
    "        # Apply the function to the date_column and create a new column\n",
    "        new_data_df['game_date'] = new_data_df['Date'].apply(lambda date: clean_date(date, current_year))\n",
    "        new_data_df['Date'] = new_data_df['game_date']\n",
    "\n",
    "        # Ensure the 'Date' column in new_data_df and 'game_date' column in game_pks are in datetime format\n",
    "        new_data_df['Date'] = pd.to_datetime(new_data_df['Date'])\n",
    "        game_pks['game_date'] = pd.to_datetime(game_pks['game_date'])\n",
    "\n",
    "        # Map the team abbreviations to full team names\n",
    "        new_data_df['team_id'] = new_data_df['Tm'].map(team_id_mapping)\n",
    "        new_data_df['opp_id'] = new_data_df['Opp'].map(team_id_mapping)\n",
    "\n",
    "        # Initialize a new column in new_data_df for game_id\n",
    "        new_data_df['game_id'] = None\n",
    "\n",
    "        # Iterate over the rows in new_data_df to find the corresponding game_id in game_pks\n",
    "        for index, row in new_data_df.iterrows():\n",
    "            # Filter the game_pks for the matching date and teams\n",
    "            game_day_matches = game_pks[\n",
    "                (game_pks['game_date'] == row['Date']) &\n",
    "                (\n",
    "                    ((game_pks['home_id'] == row['team_id']) & (game_pks['away_id'] == row['opp_id'])) |\n",
    "                    ((game_pks['home_id'] == row['opp_id']) & (game_pks['away_id'] == row['team_id']))\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Check the 'dbl' column to assign the correct game_id\n",
    "            if not game_day_matches.empty:\n",
    "                if row['dbl'] == 1:\n",
    "                    # For the first game of a double-header\n",
    "                    game_id = game_day_matches.iloc[0]['game_id']\n",
    "                elif row['dbl'] == 2:\n",
    "                    # For the second game of a double-header\n",
    "                    if len(game_day_matches) > 1:\n",
    "                        game_id = game_day_matches.iloc[1]['game_id']\n",
    "                    else:\n",
    "                        game_id = game_day_matches.iloc[0]['game_id']\n",
    "                else:\n",
    "                    # For days without double-headers or unmarked double-headers, take the first game\n",
    "                    game_id = game_day_matches.iloc[0]['game_id']\n",
    "                new_data_df.at[index, 'game_id'] = game_id\n",
    "            else:\n",
    "                print(f\"BAD - NO GAME MATCHES FOUND for {id} on {row['Date']}\")\n",
    "\n",
    "        # Concatenate the new data with the existing data, ensuring no duplicates\n",
    "        if not player_df.empty:\n",
    "            combined_df = pd.concat([player_df, new_data_df]).drop_duplicates(subset=['game_id'])\n",
    "        else:\n",
    "            combined_df = new_data_df\n",
    "\n",
    "        # Save the updated player data to a CSV file\n",
    "        combined_df.to_csv(player_file_path, index=False)\n",
    "\n",
    "    print(f'All {player_type} IDs processed and saved')\n",
    "\n",
    "# Process batter and pitcher data   \n",
    "process_player_data(active_batter_ids, player_type='batter')\n",
    "process_player_data(active_pitcher_ids, player_type='pitcher')\n",
    "\n",
    "print('\\n\\nPlayer stats updated.\\nNow generating custom stats.\\n')\n",
    "\n",
    "# =================================================== CUSTOM STATS ==============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "idlist = pd.read_csv('batter_ids.csv')\n",
    "batter_ids = idlist.key_bbref\n",
    "\n",
    "game_pks = pd.read_csv('game_pks.csv')\n",
    "\n",
    "# Define function to create an empty DataFrame with the correct structure\n",
    "def create_empty_stats_df():\n",
    "    columns = ['Rk', 'Gcar', 'Gtm', 'Date', 'Tm', 'Unnamed: 5', 'Opp', 'Rslt', 'Inngs', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'BB', 'IBB', 'SO', 'HBP', 'SH', 'SF', 'ROE', 'GDP', 'SB', 'CS', 'BA', 'OBP', 'SLG', 'OPS', 'BOP', 'aLI', 'WPA', 'acLI', 'cWPA', 'RE24', 'DFS(DK)', 'DFS(FD)', 'Pos', 'dbl', 'game_date', 'team_id', 'opp_id', 'game_id']\n",
    "    empty_df = pd.DataFrame(columns=columns)\n",
    "    return empty_df\n",
    "\n",
    "\n",
    "for id in batter_ids:\n",
    "\n",
    "    if not id or pd.isna(id):\n",
    "        continue\n",
    "\n",
    "    file_path = f'batters/{id}_batting.csv'\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Remove the irrelevant column 'Gtm'\n",
    "    df = df.drop(columns=['Gtm'])\n",
    "\n",
    "    # Ensure the 'game_date' column is in datetime format\n",
    "    df['game_date'] = pd.to_datetime(df['game_date'])\n",
    "\n",
    "    # Extract the year from the 'game_date' column\n",
    "    df['season'] = df['game_date'].dt.year\n",
    "\n",
    "    # Clean non-numeric values in numeric columns\n",
    "    def clean_numeric(value):\n",
    "        try:\n",
    "            value = str(value).replace('\\xa0', '').replace('(', '').replace(')', '').replace(',', '')\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "    # Define columns to convert to numeric\n",
    "    numeric_columns = ['PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'BB', 'IBB', 'SO', 'HBP', 'SH', 'SF', 'ROE', 'GDP', 'SB', 'CS', 'DFS(DK)', 'DFS(FD)']\n",
    "\n",
    "    # Apply cleaning function to numeric columns\n",
    "    for col in numeric_columns:\n",
    "        df[col] = df[col].apply(clean_numeric)\n",
    "\n",
    "    # Fill NaN values with 0 for numerical calculations\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(0)\n",
    "\n",
    "    # Ensure columns are of correct numeric type\n",
    "    df[numeric_columns] = df[numeric_columns].astype(float)\n",
    "\n",
    "    # Define functions to calculate required statistics\n",
    "    def calculate_avg(df):\n",
    "        return df['H'] / df['AB']\n",
    "\n",
    "    def calculate_obp(df):\n",
    "        return (df['H'] + df['BB'] + df['HBP']) / (df['AB'] + df['BB'] + df['HBP'] + df['SF'])\n",
    "\n",
    "    def calculate_slg(df):\n",
    "        return (df['H'] + 2*df['2B'] + 3*df['3B'] + 4*df['HR']) / df['AB']\n",
    "\n",
    "    def calculate_ops(df):\n",
    "        return calculate_obp(df) + calculate_slg(df)\n",
    "\n",
    "    def calculate_extra_base_hits(df):\n",
    "        return df['2B'] + df['3B'] + df['HR']\n",
    "\n",
    "    def calculate_total_bases(df):\n",
    "        return df['H'] + df['2B'] + 2*df['3B'] + 3*df['HR']\n",
    "\n",
    "    def calculate_rolling_stats(df, window, suffix):\n",
    "        rolling_df = df.rolling(window=window, min_periods=1).sum()\n",
    "        rolling_df['AVG'] = calculate_avg(rolling_df)\n",
    "        rolling_df['OBP'] = calculate_obp(rolling_df)\n",
    "        rolling_df['SLG'] = calculate_slg(rolling_df)\n",
    "        rolling_df['OPS'] = calculate_ops(rolling_df)\n",
    "        rolling_df['XB'] = calculate_extra_base_hits(rolling_df)\n",
    "        rolling_df['TB'] = calculate_total_bases(rolling_df)\n",
    "        rolling_df = rolling_df[['AVG', 'OBP', 'SLG', 'OPS', 'SB', 'CS', 'XB', 'TB', 'SO']]\n",
    "        rolling_df.columns = [f'{col}_{suffix}' for col in rolling_df.columns]\n",
    "        \n",
    "        # Round the stats to 3 decimal points\n",
    "        rolling_df = rolling_df.round(3)\n",
    "        \n",
    "        return rolling_df\n",
    "\n",
    "    # Exclude non-numeric columns from rolling stats calculation\n",
    "    rolling_df = df[numeric_columns].copy()\n",
    "\n",
    "    # Calculate rolling stats for the last 20 games and shift by one row\n",
    "    rolling_stats_20 = calculate_rolling_stats(rolling_df, 20, '20').shift(1).fillna(0)\n",
    "\n",
    "    # Calculate rolling stats for the last 10 games and shift by one row\n",
    "    rolling_stats_10 = calculate_rolling_stats(rolling_df, 10, '10').shift(1).fillna(0)\n",
    "\n",
    "    # Calculate rolling stats for the last 5 games and shift by one row\n",
    "    rolling_stats_5 = calculate_rolling_stats(rolling_df, 5, '5').shift(1).fillna(0)\n",
    "\n",
    "    # Calculate rolling stats for the last 5 games and shift by one row\n",
    "    rolling_stats_3 = calculate_rolling_stats(rolling_df, 3, '3').shift(1).fillna(0)\n",
    "\n",
    "    # Calculate season-long stats for each year and shift by one row\n",
    "    season_stats = pd.DataFrame()\n",
    "    for year in range(2021, 2025):\n",
    "        season_df = df[df['season'] == year][numeric_columns].copy()\n",
    "        season_cumsum = season_df.cumsum().shift(1).fillna(0)\n",
    "        season_cumsum['AVG'] = calculate_avg(season_cumsum)\n",
    "        season_cumsum['OBP'] = calculate_obp(season_cumsum)\n",
    "        season_cumsum['SLG'] = calculate_slg(season_cumsum)\n",
    "        season_cumsum['OPS'] = calculate_ops(season_cumsum)\n",
    "        season_cumsum['XB'] = calculate_extra_base_hits(season_cumsum)\n",
    "        season_cumsum['TB'] = calculate_total_bases(season_cumsum)\n",
    "        season_cumsum = season_cumsum[['AVG', 'OBP', 'SLG', 'OPS', 'SB', 'CS', 'XB', 'TB', 'SO']]\n",
    "        season_cumsum.columns = [f'{col}_current' for col in season_cumsum.columns]\n",
    "        season_stats = pd.concat([season_stats, season_cumsum])\n",
    "\n",
    "    # Ensure the season_stats index aligns with the original dataframe\n",
    "    season_stats.index = df.index\n",
    "\n",
    "    # Combine all the stats into a single dataframe\n",
    "    final_df = pd.concat([df, rolling_stats_20, rolling_stats_10, rolling_stats_5, rolling_stats_3, season_stats], axis=1)\n",
    "\n",
    "    # Round the combined dataframe stats to 3 decimal points\n",
    "    final_df = final_df.round(3)\n",
    "\n",
    "    # Display the combined dataframe\n",
    "    print(final_df.tail())\n",
    "\n",
    "    # Save the combined stats to a CSV file\n",
    "    final_df.to_csv(f'batters/{id}_stats_batting.csv', index=False)\n",
    "\n",
    "    print(f\"Generated stats for {id} and saved to CSV file.\")\n",
    "\n",
    "    import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to clean numeric values\n",
    "def clean_numeric(value):\n",
    "    try:\n",
    "        value = str(value).replace('\\xa0', '').replace('(', '').replace(')', '').replace(',', '')\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# Function to convert IP notation to real numbers\n",
    "def convert_ip_to_real(ip):\n",
    "    if pd.isna(ip):\n",
    "        return np.nan\n",
    "    ip_str = str(ip)\n",
    "    if '.' in ip_str:\n",
    "        parts = ip_str.split('.')\n",
    "        whole = int(parts[0])\n",
    "        fraction = int(parts[1]) if len(parts) > 1 else 0\n",
    "        if fraction == 1:\n",
    "            return whole + 1/3\n",
    "        elif fraction == 2:\n",
    "            return whole + 2/3\n",
    "        else:\n",
    "            return whole\n",
    "    return float(ip)\n",
    "\n",
    "# Function to calculate ERA\n",
    "def calculate_era(df):\n",
    "    return (df['ER'] * 9) / df['IP_real']\n",
    "\n",
    "# Function to calculate WHIP\n",
    "def calculate_whip(df):\n",
    "    return (df['H'] + df['BB']) / df['IP_real']\n",
    "\n",
    "# Function to calculate extra base hits against\n",
    "def calculate_extra_base_hits_against(df):\n",
    "    return df['2B'] + df['3B'] + df['HR']\n",
    "\n",
    "# Function to calculate total bases against\n",
    "def calculate_total_bases_against(df):\n",
    "    return df['H'] + df['2B'] + 2 * df['3B'] + 3 * df['HR']\n",
    "\n",
    "# Function to calculate rolling stats\n",
    "def calculate_rolling_stats(df, window, suffix):\n",
    "    rolling_df = df.rolling(window=window, min_periods=1).sum()\n",
    "    rolling_df['ERA'] = calculate_era(rolling_df)\n",
    "    rolling_df['WHIP'] = calculate_whip(rolling_df)\n",
    "    rolling_df['XB_against'] = calculate_extra_base_hits_against(rolling_df)\n",
    "    rolling_df['TB_against'] = calculate_total_bases_against(rolling_df)\n",
    "    rolling_df = rolling_df[['IP_real', 'H', 'BF', 'HR', 'R', 'ER', 'BB', 'SO', 'XB_against', 'TB_against', 'ERA', 'WHIP']]\n",
    "    rolling_df.columns = [f'{col}_{suffix}' for col in rolling_df.columns]\n",
    "    return rolling_df.round(3)\n",
    "\n",
    "# Load pitcher IDs\n",
    "idlist = pd.read_csv('pitcher_ids.csv')\n",
    "pitcher_ids = idlist.key_bbref\n",
    "\n",
    "# Load game PKs (if needed)\n",
    "game_pks = pd.read_csv('game_pks.csv')\n",
    "\n",
    "for id in pitcher_ids:\n",
    "\n",
    "    if not id or pd.isna(id):\n",
    "        continue\n",
    "\n",
    "    file_path = f'pitchers/{id}_pitching.csv' \n",
    "    \n",
    "    if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"File for ID {id} is empty.\")\n",
    "            continue\n",
    "        except pd.errors.ParserError:\n",
    "            print(f\"File for ID {id} is improperly formatted.\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"File for ID {id} does not exist or is empty.\")\n",
    "        continue\n",
    "\n",
    "    # Remove the irrelevant column 'Gtm'\n",
    "    df = df.drop(columns=['Gtm'])\n",
    "\n",
    "    # Ensure the 'game_date' column is in datetime format\n",
    "    df['game_date'] = pd.to_datetime(df['game_date'])\n",
    "\n",
    "    # Extract the year from the 'game_date' column\n",
    "    df['season'] = df['game_date'].dt.year\n",
    "\n",
    "    # Define columns to convert to numeric\n",
    "    numeric_columns = ['IP', 'H', 'R', 'ER', 'BB', 'SO', 'HR', 'BF', '2B', '3B', 'IBB']\n",
    "\n",
    "    # Apply cleaning function to numeric columns\n",
    "    for col in numeric_columns:\n",
    "        df[col] = df[col].apply(clean_numeric)\n",
    "\n",
    "    # Fill NaN values with 0 for numerical calculations\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(0)\n",
    "\n",
    "    # Ensure columns are of correct numeric type\n",
    "    df[numeric_columns] = df[numeric_columns].astype(float)\n",
    "\n",
    "    # Create the IP_real column\n",
    "    df['IP_real'] = df['IP'].apply(convert_ip_to_real)\n",
    "\n",
    "    # Exclude non-numeric columns from rolling stats calculation\n",
    "    rolling_df = df[numeric_columns + ['IP_real']].copy()\n",
    "\n",
    "    # Calculate rolling stats for the last 20 games and shift by one row\n",
    "    rolling_stats_20 = calculate_rolling_stats(rolling_df, 20, '20').shift(1).fillna(0)\n",
    "\n",
    "    # Calculate rolling stats for the last 20 games and shift by one row\n",
    "    rolling_stats_10 = calculate_rolling_stats(rolling_df, 10, '10').shift(1).fillna(0)\n",
    "\n",
    "    # Calculate rolling stats for the last 5 games and shift by one row\n",
    "    rolling_stats_5 = calculate_rolling_stats(rolling_df, 5, '5').shift(1).fillna(0)\n",
    "\n",
    "    # Calculate rolling stats for the last 20 games and shift by one row\n",
    "    rolling_stats_3 = calculate_rolling_stats(rolling_df, 3, '3').shift(1).fillna(0)\n",
    "\n",
    "    # Calculate season-long stats for each year and shift by one row\n",
    "    season_stats = pd.DataFrame()\n",
    "    for year in df['season'].unique():\n",
    "        season_df = df[df['season'] == year][numeric_columns + ['IP_real']].copy()\n",
    "        season_cumsum = season_df.cumsum().shift(1).fillna(0)\n",
    "        season_cumsum['ERA'] = calculate_era(season_cumsum)\n",
    "        season_cumsum['WHIP'] = calculate_whip(season_cumsum)\n",
    "        season_cumsum['XB_against'] = calculate_extra_base_hits_against(season_cumsum)\n",
    "        season_cumsum['TB_against'] = calculate_total_bases_against(season_cumsum)\n",
    "        season_cumsum = season_cumsum[['IP_real', 'H', 'BF', 'HR', 'R', 'ER', 'BB', 'SO', 'XB_against', 'TB_against', 'ERA', 'WHIP']]\n",
    "        season_cumsum.columns = [f'{col}_current' for col in season_cumsum.columns]\n",
    "        season_stats = pd.concat([season_stats, season_cumsum])\n",
    "\n",
    "    # Ensure the season_stats index aligns with the original dataframe\n",
    "    season_stats.index = df.index\n",
    "\n",
    "    # Combine all the stats into a single dataframe\n",
    "    final_df = pd.concat([df, rolling_stats_20, rolling_stats_10, rolling_stats_5, rolling_stats_3, season_stats], axis=1)\n",
    "\n",
    "    # Round the combined dataframe stats to 3 decimal points\n",
    "    final_df = final_df.round(3)\n",
    "\n",
    "    # Display the combined dataframe\n",
    "    print(final_df.tail())\n",
    "\n",
    "    # Save the combined stats to a CSV file\n",
    "    final_df.to_csv(f'pitchers/{id}_stats_pitching.csv', index=False)\n",
    "\n",
    "    print(f\"Generated stats for {id} and saved to CSV file.\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_player_stats(bbref_id, player_type, game_id):\n",
    "    \"\"\"\n",
    "    Get the player's stats for the specific game_id. If not available, return the most recent stats.\n",
    "    \"\"\"\n",
    "    stats_dir = 'batters' if player_type == 'batting' else 'pitchers'\n",
    "    stats_file = os.path.join(stats_dir, f'{bbref_id}_stats_{player_type}.csv')\n",
    "    \n",
    "    if not os.path.exists(stats_file):\n",
    "        print(f\"Stats file for {bbref_id} not found ({player_type}).\")\n",
    "        return None\n",
    "    \n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    game_stats = stats_df[stats_df['game_id'] == game_id]\n",
    "    \n",
    "    if not game_stats.empty:\n",
    "        return game_stats.iloc[0]\n",
    "    else:\n",
    "        return stats_df.iloc[-1]\n",
    "\n",
    "def process_game(game_id):\n",
    "    # Read the gamelog file\n",
    "    game_file = f'gamelogs/game_{game_id}.csv'\n",
    "    if not os.path.exists(game_file):\n",
    "        print(f\"Gamelog file for game {game_id} not found.\")\n",
    "        return\n",
    "    \n",
    "    game_df = pd.read_csv(game_file)\n",
    "    game_data = game_df.iloc[0].to_dict()\n",
    "    \n",
    "    # Define relevant columns for batters and pitchers\n",
    "    batter_columns = ['AVG_20', 'OBP_20', 'SLG_20', 'OPS_20', 'SB_20', 'CS_20', 'XB_20', 'TB_20', 'SO_20',\n",
    "                      'AVG_10', 'OBP_10', 'SLG_10', 'OPS_10', 'SB_10', 'CS_10', 'XB_10', 'TB_10', 'SO_10',\n",
    "                      'AVG_5', 'OBP_5', 'SLG_5', 'OPS_5', 'SB_5', 'CS_5', 'XB_5', 'TB_5', 'SO_5',\n",
    "                      'AVG_3', 'OBP_3', 'SLG_3', 'OPS_3', 'SB_3', 'CS_3', 'XB_3', 'TB_3', 'SO_3']\n",
    "    pitcher_columns = ['IP_real_20', 'ERA', 'H_20', 'BF_20', 'HR_20', 'R_20', 'ER_20', 'BB_20', 'SO_20', 'XB_against_20',\n",
    "                       'TB_against_20', 'ERA_20', 'WHIP_20', 'IP_real_10', 'H_10', 'BF_10', 'HR_10', 'R_10', 'ER_10', 'BB_10', 'SO_10', 'XB_against_10',\n",
    "                       'TB_against_10', 'ERA_10', 'WHIP_10', 'IP_real_5', 'H_5', 'BF_5', 'HR_5', 'R_5', 'ER_5', 'BB_5',\n",
    "                       'SO_5', 'XB_against_5', 'TB_against_5', 'ERA_5', 'WHIP_5', 'IP_real_3', 'H_3', 'BF_3', 'HR_3', 'R_3', 'ER_3', 'BB_3',\n",
    "                       'SO_3', 'XB_against_3', 'TB_against_3', 'ERA_3', 'WHIP_3']\n",
    "    \n",
    "    # Fetch stats for each batter\n",
    "    for i in range(1, 10):\n",
    "        for team in ['Away', 'Home']:\n",
    "            bbref_id = game_data.get(f'{team}_Batter{i}_bbrefID')\n",
    "            if bbref_id:\n",
    "                stats = get_player_stats(bbref_id, 'batting', game_id)\n",
    "                if stats is not None:\n",
    "                    for col in batter_columns:\n",
    "                        game_data[f'{team}_Batter{i}_{col}'] = stats.get(col, '')\n",
    "            else:\n",
    "                print(f'missing bbrefID for game {game_id}')\n",
    "\n",
    "    # Fetch stats for each pitcher\n",
    "    for team in ['Away', 'Home']:\n",
    "        for i in range(1, 11):\n",
    "            role = 'SP' if i == 1 else f'P_{i}'\n",
    "            bbref_id = game_data.get(f'{team}_{role}_bbrefID')\n",
    "            if bbref_id:\n",
    "                stats = get_player_stats(bbref_id, 'pitching', game_id)\n",
    "                if stats is not None:\n",
    "                    for col in pitcher_columns:\n",
    "                        game_data[f'{team}_{role}_{col}'] = stats.get(col, '')\n",
    "\n",
    "    # Fetch stats for each bullpen pitcher\n",
    "    for team in ['Away', 'Home']:\n",
    "        for i in range(1, 15):  # Adjust the range according to your maximum expected number of bullpen pitchers\n",
    "            role = f'bullpen_{i}'\n",
    "            bbref_id = game_data.get(f'{team}_{role}_bbrefID')\n",
    "            if bbref_id:\n",
    "                stats = get_player_stats(bbref_id, 'pitching', game_id)\n",
    "                if stats is not None:\n",
    "                    for col in pitcher_columns:\n",
    "                        game_data[f'{team}_{role}_{col}'] = stats.get(col, '')\n",
    "    \n",
    "    # Create a DataFrame from the updated game data\n",
    "    updated_game_df = pd.DataFrame([game_data])\n",
    "    \n",
    "    # Save the updated game data to a new CSV file\n",
    "    output_file = f'gamelogs/gamestats_{game_id}.csv'\n",
    "    updated_game_df.to_csv(output_file, index=False)\n",
    "    print(f\"Processed and saved game stats for game {game_id} to {output_file}\")\n",
    "\n",
    "def process_recent_games(num_recent_games):\n",
    "    game_pks_file = 'game_pks.csv'\n",
    "    if not os.path.exists(game_pks_file):\n",
    "        print(f\"{game_pks_file} not found.\")\n",
    "        return\n",
    "\n",
    "    game_pks_df = pd.read_csv(game_pks_file)\n",
    "    recent_game_pks = game_pks_df.tail(num_recent_games)['game_id'].tolist()\n",
    "    \n",
    "    for game_id in recent_game_pks:\n",
    "        process_game(game_id)\n",
    "\n",
    "# Input the number of most recent games to process\n",
    "num_recent_games = 100\n",
    "process_recent_games(num_recent_games)\n",
    "\n",
    "print('\\n\\nCustom stats added to gamelogs.\\n\\nSUCCESS - THIS FILE IS COMPLETE.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLBpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
