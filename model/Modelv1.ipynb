{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import xgboost as xgb\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesse\\AppData\\Local\\Temp\\ipykernel_18348\\1766892526.py:2: DtypeWarning: Columns (774,982,1128,1129,1180,1181,1232,1233,1297,1505,1599,1600,1651,1652,1703,1704,1797,1798,1800,1801,1803,1804,1845,1846,1848,1849) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('masterdata.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('masterdata.csv')\n",
    "\n",
    "#Remove first 250 rows (because many custom stat values are empty)\n",
    "df = df.tail(len(df)-255)\n",
    "\n",
    "# Convert 'game_date' column to datetime objects\n",
    "df['game_date'] = pd.to_datetime(df['game_date'])\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Filter out rows with today's date\n",
    "df = df[df['game_date'] != today]\n",
    "\n",
    "# Drop the columns containing 'Name', 'ID', or '_P_'\n",
    "columns_to_drop = [col for col in df.columns if 'Name' in col or 'ID' in col or '_P_' in col or 'bbrefID' in col]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop rows with missing values in the target variable\n",
    "df = df.dropna(subset=['over_under_runline'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['over_under_target', 'runs_total', 'game_date', 'runs_home', 'runs_away', 'game_id', 'home_name', 'away_name'])\n",
    "y = df['over_under_target']\n",
    "\n",
    "# You can now proceed to train your model using X and y\n",
    "# Example: Train a RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Accuracy: 0.6284848484848485\n",
      "Confusion Matrix:\n",
      " [[454 326]\n",
      " [287 583]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.60       780\n",
      "           1       0.64      0.67      0.66       870\n",
      "\n",
      "    accuracy                           0.63      1650\n",
      "   macro avg       0.63      0.63      0.63      1650\n",
      "weighted avg       0.63      0.63      0.63      1650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline with imputer, scaler, and model\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('var_thresh', VarianceThreshold(threshold=0.1)),  # Remove low-variance features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Define a parameter grid for XGBoost\n",
    "param_grid1 = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__learning_rate': [0.01, 0.1],\n",
    "    'model__max_depth': [3, 5, 9],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0],\n",
    "    'model__gamma': [0, 0.1],\n",
    "    'model__min_child_weight': [1, 3, 7]\n",
    "}\n",
    "\n",
    "param_grid2 = {\n",
    "    'model__n_estimators': [25, 75, 150, 250],\n",
    "    'model__learning_rate': [0.05, 0.15],\n",
    "    'model__max_depth': [6, 12, 15],\n",
    "    'model__subsample': [0.25, 0.5, 0.9],\n",
    "    'model__colsample_bytree': [0.2, 0.4, 0.6],\n",
    "    'model__gamma': [0.05, 0.2, 0.3],\n",
    "    'model__min_child_weight': [4, 8, 12]\n",
    "}\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipeline, param_grid1, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n",
    "print('Classification Report:\\n', class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1650 6596\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model\n",
    "joblib.dump(best_model, 'xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesse\\AppData\\Local\\Temp\\ipykernel_22496\\2003368610.py:2: DtypeWarning: Columns (534,612,613,640,641,668,669,705,817,895,896,923,924,996,997,999,1000,1041,1042,1044,1045) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df0 = pd.read_csv('masterdata.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "Accuracy: 0.639030612244898\n",
      "Confusion Matrix:\n",
      " [[325  97]\n",
      " [186 176]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.77      0.70       422\n",
      "           1       0.64      0.49      0.55       362\n",
      "\n",
      "    accuracy                           0.64       784\n",
      "   macro avg       0.64      0.63      0.63       784\n",
      "weighted avg       0.64      0.64      0.63       784\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb_model_0.pkl']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df0 = pd.read_csv('masterdata.csv')\n",
    "\n",
    "# Convert 'game_date' column to datetime objects\n",
    "df0['game_date'] = pd.to_datetime(df0['game_date'])\n",
    "\n",
    "# Change the 'push' games to equal 0.\n",
    "df0.loc[df0['over_under_runline'] == df0['runs_total'], 'over_under_target'] = 0\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Filter out rows with today's date\n",
    "df0 = df0[df0['game_date'] != today]\n",
    "\n",
    "# Drop the columns containing 'Name', 'ID', or '_P_'\n",
    "columns_to_drop = [col for col in df0.columns if 'Name' in col or 'ID' in col or '_P_' in col or 'bbrefID' in col]\n",
    "df0 = df0.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop rows with missing values in the target variable\n",
    "df0 = df0.dropna(subset=['over_under_runline'])\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = df0.drop(columns=['over_under_target', 'runs_total', 'game_date', 'runs_home', 'runs_away', 'game_id', 'home_name', 'away_name'])\n",
    "y = df0['over_under_target']\n",
    "\n",
    "# You can now proceed to train your model using X and y\n",
    "# Example: Train a RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Define a pipeline with imputer, scaler, and model\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('var_thresh', VarianceThreshold(threshold=0.1)),  # Remove low-variance features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Define a more granular parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 150, 200],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0],\n",
    "    'model__gamma': [0, 0.1],\n",
    "    'model__min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n",
    "print('Classification Report:\\n', class_report)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'xgb_model_0.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 0-Trained Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesse\\AppData\\Local\\Temp\\ipykernel_22496\\241514570.py:2: DtypeWarning: Columns (534,612,613,640,641,668,669,705,817,895,896,923,924,996,997,999,1000,1041,1042,1044,1045) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('masterdata.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 8088: Under the runline\n",
      "Game 8089: Under the runline\n",
      "Game 8090: Under the runline\n",
      "Game 8091: Under the runline\n",
      "Game 8092: Under the runline\n",
      "Game 8093: Under the runline\n",
      "Game 8094: Under the runline\n",
      "Game 8095: Over the runline\n",
      "Game 8096: Under the runline\n",
      "Game 8097: Over the runline\n",
      "Game 8098: Under the runline\n",
      "Game 8099: Under the runline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesse\\AppData\\Local\\Temp\\ipykernel_22496\\241514570.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  todays_games['prediction'] = predictions\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('masterdata.csv')\n",
    "\n",
    "# Convert 'game_date' column to datetime objects\n",
    "df['game_date'] = pd.to_datetime(df['game_date'])\n",
    "\n",
    "# Change the 'push' games to equal 0.\n",
    "df0.loc[df0['over_under_runline'] == df0['runs_total'], 'over_under_target'] = 0\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Separate the data for today's games\n",
    "todays_games = df[df['game_date'] == today]\n",
    "\n",
    "# Check if there are any games today\n",
    "if todays_games.empty:\n",
    "    print(\"No games found for today.\")\n",
    "else:\n",
    "    # Define the columns to drop\n",
    "    columns_to_drop = [col for col in df.columns if 'Name' in col or 'ID' in col or '_P_' in col or '12' in col or '13' in col or '14' in col or '15'in col ]\n",
    "    columns_to_drop.extend(['over_under_target', 'runs_total', 'game_date', 'runs_home', 'runs_away', 'game_id', 'home_name', 'away_name']) \n",
    "\n",
    "    # Drop the unnecessary columns\n",
    "    X_todays_games = todays_games.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Load the trained model (assuming it's saved as 'model.pkl')\n",
    "    xgb_model = joblib.load('xgb_model_0.pkl')\n",
    "\n",
    "# Make predictions\n",
    "predictions = xgb_model.predict(X_todays_games)\n",
    "\n",
    "# Interpret and display the predictions\n",
    "todays_games['prediction'] = predictions\n",
    "for i, row in todays_games.iterrows():\n",
    "    result = 'Over' if row['prediction'] == 1 else 'Under'\n",
    "    print(f\"Game {i + 2}: {result} the runline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLBpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
