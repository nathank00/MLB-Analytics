{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine individual player files into a combined file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def combine_player_data(preprocessed_folder):\n",
    "    \"\"\"\n",
    "    Combines all preprocessed player data files into a single DataFrame and sorts them by game date.\n",
    "\n",
    "    Parameters:\n",
    "    - preprocessed_folder (str): The folder containing all the preprocessed player files.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Combined and sorted player data.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # Loop through all files in the preprocessed folder\n",
    "    for file_name in os.listdir(preprocessed_folder):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(preprocessed_folder, file_name)\n",
    "            player_df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Append the player's data to the list\n",
    "            all_data.append(player_df)\n",
    "    \n",
    "    # Combine all the player data into a single DataFrame\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Ensure the data is sorted by 'GAME_DATE'\n",
    "    combined_df['GAME_DATE'] = pd.to_datetime(combined_df['GAME_DATE'])\n",
    "    combined_df = combined_df.sort_values(by='GAME_DATE', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Example usage:\n",
    "preprocessed_folder = 'preprocessed_players_stats'\n",
    "combined_player_data = combine_player_data(preprocessed_folder)\n",
    "\n",
    "# Optionally, save the combined data for further inspection\n",
    "combined_player_data.to_csv('combined_player_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to preprocess player data including date encoding\n",
    "def preprocess_player_data(player_df):\n",
    "    # Step 1: Convert WL to 1 for Win and 0 for Loss\n",
    "    player_df['WL'] = player_df['WL'].apply(lambda x: 1 if x == 'W' else 0)\n",
    "    \n",
    "    # # Step 2: Drop irrelevant columns (customize this based on your needs)\n",
    "    # drop_columns = ['VIDEO_AVAILABLE', 'PLUS_MINUS', 'SEASON_ID', 'Player_ID']  # Modify the list as per your data\n",
    "    # player_df = player_df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "    # Step 3: Encode the GAME_DATE column\n",
    "    # You can choose one or more of the following methods:\n",
    "\n",
    "    # Method 1: Extract date components (year, month, day)\n",
    "    player_df['GAME_YEAR'] = player_df['GAME_DATE'].dt.year\n",
    "    player_df['GAME_MONTH'] = player_df['GAME_DATE'].dt.month\n",
    "    player_df['GAME_DAY'] = player_df['GAME_DATE'].dt.day\n",
    "\n",
    "    # Method 2: Calculate days since a reference date\n",
    "    reference_date = pd.to_datetime('2024-10-22')\n",
    "    player_df['DAYS_SINCE_REF'] = (player_df['GAME_DATE'] - reference_date).dt.days\n",
    "\n",
    "    # Method 3: Cyclic encoding of month and day\n",
    "    player_df['MONTH_SIN'] = np.sin(2 * np.pi * player_df['GAME_MONTH'] / 12)\n",
    "    player_df['MONTH_COS'] = np.cos(2 * np.pi * player_df['GAME_MONTH'] / 12)\n",
    "    player_df['DAY_SIN'] = np.sin(2 * np.pi * player_df['GAME_DAY'] / 31)\n",
    "    player_df['DAY_COS'] = np.cos(2 * np.pi * player_df['GAME_DAY'] / 31)\n",
    "\n",
    "    # Step 4: Drop the original GAME_DATE column (now encoded)\n",
    "    player_df.drop(columns=['GAME_DATE'], inplace=True)\n",
    "\n",
    "    # Return the preprocessed DataFrame\n",
    "    return player_df\n",
    "\n",
    "combined_player_data = preprocess_player_data(combined_player_data)\n",
    "\n",
    "# Optionally, save the combined data for further inspection\n",
    "combined_player_data.to_csv('combined_player_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def prepare_data_for_training(combined_df):\n",
    "    \"\"\"\n",
    "    Prepares the combined player data for training an XGBoost model by selecting relevant features,\n",
    "    encoding categorical data, and splitting the data into train/test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - combined_df (DataFrame): The combined player game log data.\n",
    "\n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test: Training and test sets for the model.\n",
    "    \"\"\"\n",
    "    # Feature selection: choose relevant features (adjust these as needed)\n",
    "    features = [\n",
    "        \"SEASON_ID\", \"WL\", \"OPP_TEAM\", # Game Context\n",
    "        \"GAME_YEAR\", \"GAME_MONTH\", \"GAME_DAY\", \"DAYS_SINCE_REF\", \"MONTH_SIN\", \"MONTH_COS\", \"DAY_SIN\", \"DAY_COS\", # Game Date Context\n",
    "        \"MIN\", \"FGM\", \"FGA\", \"FG_PCT\", \"FG3M\", \"FG3A\", \"FG3_PCT\", \"FTM\" , \"FTA\", \"FT_PCT\", \"PTS\", # Core Stats\n",
    "        \"OREB\", \"DREB\", \"REB\", \"AST\", \"STL\", \"BLK\", \"TOV\", \"PF\", # Extra Non-point Stats\n",
    "        \"PLUS_MINUS\", # Advanced Stats\n",
    "        # Rolling Statistics\n",
    "        \"ROLLING_PTS_20_GAMES\", \"ROLLING_MIN_20_GAMES\", \"ROLLING_FGA_20_GAMES\", \"ROLLING_FGM_20_GAMES\", \"ROLLING_AST_20_GAMES\", \"ROLLING_REB_20_GAMES\", \"ROLLING_STL_20_GAMES\", \"ROLLING_BLK_20_GAMES\", \"ROLLING_TOV_20_GAMES\", \"ROLLING_PF_20_GAMES\",\n",
    "        \"ROLLING_PTS_10_GAMES\", \"ROLLING_MIN_10_GAMES\", \"ROLLING_FGA_10_GAMES\", \"ROLLING_FGM_10_GAMES\", \"ROLLING_AST_10_GAMES\", \"ROLLING_REB_10_GAMES\", \"ROLLING_STL_10_GAMES\", \"ROLLING_BLK_10_GAMES\", \"ROLLING_TOV_10_GAMES\", \"ROLLING_PF_10_GAMES\",\n",
    "        \"ROLLING_PTS_5_GAMES\", \"ROLLING_MIN_5_GAMES\", \"ROLLING_FGA_5_GAMES\", \"ROLLING_FGM_5_GAMES\", \"ROLLING_AST_5_GAMES\", \"ROLLING_REB_5_GAMES\", \"ROLLING_STL_5_GAMES\", \"ROLLING_BLK_5_GAMES\", \"ROLLING_TOV_5_GAMES\", \"ROLLING_PF_5_GAMES\",\n",
    "        \"ROLLING_PTS_3_GAMES\", \"ROLLING_MIN_3_GAMES\", \"ROLLING_FGA_3_GAMES\", \"ROLLING_FGM_3_GAMES\", \"ROLLING_AST_3_GAMES\", \"ROLLING_REB_3_GAMES\", \"ROLLING_STL_3_GAMES\", \"ROLLING_BLK_3_GAMES\", \"ROLLING_TOV_3_GAMES\", \"ROLLING_PF_3_GAMES\",\n",
    "        \"CUM_PTS_SEASON\", \"CUM_MIN_SEASON\", \"CUM_FGM_SEASON\", \"CUM_FGA_SEASON\", \"CUM_AST_SEASON\", \"CUM_REB_SEASON\" # Cumulative Season Stats\n",
    "    ]\n",
    "    \n",
    "    # Ensure no NaN values in features, fill with 0 or mean as appropriate\n",
    "    combined_df = combined_df.fillna(0)\n",
    "    \n",
    "    # Encode categorical variables (e.g., OPP_TEAM, WL)\n",
    "    label_encoder = LabelEncoder()\n",
    "    combined_df['OPP_TEAM'] = label_encoder.fit_transform(combined_df['OPP_TEAM'])\n",
    "    combined_df['WL'] = combined_df['WL'].apply(lambda x: 1 if x == 'W' else 0)\n",
    "    \n",
    "    # Input features (X) and target variable (y)\n",
    "    X = combined_df[features]\n",
    "    y = combined_df['PTS']  # Target is 'PTS' i.e. the points scored in the next game\n",
    "    \n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Example usage:\n",
    "X_train, X_test, y_train, y_test = prepare_data_for_training(combined_player_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:8.11708\teval-rmse:8.09823\n",
      "[1]\ttrain-rmse:7.30786\teval-rmse:7.29256\n",
      "[2]\ttrain-rmse:6.57944\teval-rmse:6.56743\n",
      "[3]\ttrain-rmse:5.92376\teval-rmse:5.91476\n",
      "[4]\ttrain-rmse:5.33362\teval-rmse:5.32782\n",
      "[5]\ttrain-rmse:4.80227\teval-rmse:4.79831\n",
      "[6]\ttrain-rmse:4.32403\teval-rmse:4.32265\n",
      "[7]\ttrain-rmse:3.89346\teval-rmse:3.89384\n",
      "[8]\ttrain-rmse:3.50598\teval-rmse:3.50877\n",
      "[9]\ttrain-rmse:3.15704\teval-rmse:3.16056\n",
      "[10]\ttrain-rmse:2.84293\teval-rmse:2.84749\n",
      "[11]\ttrain-rmse:2.56032\teval-rmse:2.56613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelkoo/Documents/GitHub/NBA-Analytics/nba-analytics/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [20:46:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttrain-rmse:2.30578\teval-rmse:2.31205\n",
      "[13]\ttrain-rmse:2.07666\teval-rmse:2.08359\n",
      "[14]\ttrain-rmse:1.87041\teval-rmse:1.87756\n",
      "[15]\ttrain-rmse:1.68479\teval-rmse:1.69307\n",
      "[16]\ttrain-rmse:1.51768\teval-rmse:1.52624\n",
      "[17]\ttrain-rmse:1.36732\teval-rmse:1.37690\n",
      "[18]\ttrain-rmse:1.23195\teval-rmse:1.24202\n",
      "[19]\ttrain-rmse:1.11009\teval-rmse:1.12079\n",
      "[20]\ttrain-rmse:1.00058\teval-rmse:1.01280\n",
      "[21]\ttrain-rmse:0.90192\teval-rmse:0.91504\n",
      "[22]\ttrain-rmse:0.81319\teval-rmse:0.82782\n",
      "[23]\ttrain-rmse:0.73326\teval-rmse:0.74836\n",
      "[24]\ttrain-rmse:0.66142\teval-rmse:0.67803\n",
      "[25]\ttrain-rmse:0.59677\teval-rmse:0.61496\n",
      "[26]\ttrain-rmse:0.53849\teval-rmse:0.55734\n",
      "[27]\ttrain-rmse:0.48607\teval-rmse:0.50505\n",
      "[28]\ttrain-rmse:0.43900\teval-rmse:0.45945\n",
      "[29]\ttrain-rmse:0.39651\teval-rmse:0.41725\n",
      "[30]\ttrain-rmse:0.35833\teval-rmse:0.37955\n",
      "[31]\ttrain-rmse:0.32402\teval-rmse:0.34610\n",
      "[32]\ttrain-rmse:0.29334\teval-rmse:0.31710\n",
      "[33]\ttrain-rmse:0.26555\teval-rmse:0.28989\n",
      "[34]\ttrain-rmse:0.24055\teval-rmse:0.26568\n",
      "[35]\ttrain-rmse:0.21833\teval-rmse:0.24516\n",
      "[36]\ttrain-rmse:0.19810\teval-rmse:0.22570\n",
      "[37]\ttrain-rmse:0.17993\teval-rmse:0.20834\n",
      "[38]\ttrain-rmse:0.16368\teval-rmse:0.19290\n",
      "[39]\ttrain-rmse:0.14924\teval-rmse:0.17990\n",
      "[40]\ttrain-rmse:0.13618\teval-rmse:0.16771\n",
      "[41]\ttrain-rmse:0.12446\teval-rmse:0.15685\n",
      "[42]\ttrain-rmse:0.11425\teval-rmse:0.14846\n",
      "[43]\ttrain-rmse:0.10502\teval-rmse:0.14040\n",
      "[44]\ttrain-rmse:0.09697\teval-rmse:0.13402\n",
      "[45]\ttrain-rmse:0.08950\teval-rmse:0.12725\n",
      "[46]\ttrain-rmse:0.08282\teval-rmse:0.12125\n",
      "[47]\ttrain-rmse:0.07717\teval-rmse:0.11686\n",
      "[48]\ttrain-rmse:0.07190\teval-rmse:0.11209\n",
      "[49]\ttrain-rmse:0.06725\teval-rmse:0.10791\n",
      "[50]\ttrain-rmse:0.06304\teval-rmse:0.10458\n",
      "[51]\ttrain-rmse:0.05956\teval-rmse:0.10184\n",
      "[52]\ttrain-rmse:0.05624\teval-rmse:0.09924\n",
      "[53]\ttrain-rmse:0.05328\teval-rmse:0.09696\n",
      "[54]\ttrain-rmse:0.05102\teval-rmse:0.09533\n",
      "[55]\ttrain-rmse:0.04870\teval-rmse:0.09354\n",
      "[56]\ttrain-rmse:0.04663\teval-rmse:0.09192\n",
      "[57]\ttrain-rmse:0.04480\teval-rmse:0.09047\n",
      "[58]\ttrain-rmse:0.04338\teval-rmse:0.08913\n",
      "[59]\ttrain-rmse:0.04232\teval-rmse:0.08844\n",
      "[60]\ttrain-rmse:0.04101\teval-rmse:0.08735\n",
      "[61]\ttrain-rmse:0.04011\teval-rmse:0.08662\n",
      "[62]\ttrain-rmse:0.03940\teval-rmse:0.08611\n",
      "[63]\ttrain-rmse:0.03843\teval-rmse:0.08526\n",
      "[64]\ttrain-rmse:0.03760\teval-rmse:0.08419\n",
      "[65]\ttrain-rmse:0.03681\teval-rmse:0.08346\n",
      "[66]\ttrain-rmse:0.03631\teval-rmse:0.08316\n",
      "[67]\ttrain-rmse:0.03564\teval-rmse:0.08254\n",
      "[68]\ttrain-rmse:0.03532\teval-rmse:0.08226\n",
      "[69]\ttrain-rmse:0.03476\teval-rmse:0.08173\n",
      "[70]\ttrain-rmse:0.03431\teval-rmse:0.08105\n",
      "[71]\ttrain-rmse:0.03402\teval-rmse:0.08071\n",
      "[72]\ttrain-rmse:0.03357\teval-rmse:0.08026\n",
      "[73]\ttrain-rmse:0.03341\teval-rmse:0.08012\n",
      "[74]\ttrain-rmse:0.03301\teval-rmse:0.07972\n",
      "[75]\ttrain-rmse:0.03265\teval-rmse:0.07934\n",
      "[76]\ttrain-rmse:0.03254\teval-rmse:0.07924\n",
      "[77]\ttrain-rmse:0.03239\teval-rmse:0.07903\n",
      "[78]\ttrain-rmse:0.03208\teval-rmse:0.07870\n",
      "[79]\ttrain-rmse:0.03198\teval-rmse:0.07860\n",
      "[80]\ttrain-rmse:0.03170\teval-rmse:0.07830\n",
      "[81]\ttrain-rmse:0.03154\teval-rmse:0.07800\n",
      "[82]\ttrain-rmse:0.03129\teval-rmse:0.07773\n",
      "[83]\ttrain-rmse:0.03123\teval-rmse:0.07768\n",
      "[84]\ttrain-rmse:0.03101\teval-rmse:0.07744\n",
      "[85]\ttrain-rmse:0.03090\teval-rmse:0.07735\n",
      "[86]\ttrain-rmse:0.03083\teval-rmse:0.07725\n",
      "[87]\ttrain-rmse:0.03063\teval-rmse:0.07703\n",
      "[88]\ttrain-rmse:0.03044\teval-rmse:0.07683\n",
      "[89]\ttrain-rmse:0.03040\teval-rmse:0.07679\n",
      "[90]\ttrain-rmse:0.03026\teval-rmse:0.07652\n",
      "[91]\ttrain-rmse:0.03019\teval-rmse:0.07646\n",
      "[92]\ttrain-rmse:0.03003\teval-rmse:0.07628\n",
      "[93]\ttrain-rmse:0.03001\teval-rmse:0.07626\n",
      "[94]\ttrain-rmse:0.02986\teval-rmse:0.07610\n",
      "[95]\ttrain-rmse:0.02982\teval-rmse:0.07604\n",
      "[96]\ttrain-rmse:0.02969\teval-rmse:0.07590\n",
      "[97]\ttrain-rmse:0.02967\teval-rmse:0.07588\n",
      "[98]\ttrain-rmse:0.02962\teval-rmse:0.07583\n",
      "[99]\ttrain-rmse:0.02949\teval-rmse:0.07570\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Convert training and test data to DMatrix format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set up the parameters for training\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  # Regression task\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'alpha': 10,  # L1 regularization term\n",
    "    'n_estimators': 100,  # Number of trees\n",
    "    'eval_metric': 'rmse'  # Root Mean Squared Error\n",
    "}\n",
    "\n",
    "# Specify evaluation set (test set)\n",
    "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "# Train the model\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100, evals=evallist, early_stopping_rounds=10)\n",
    "\n",
    "# Save the model if needed\n",
    "xgb_model.save_model('xgboost_NBA_model0.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Preformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0756963811127046\n",
      "MAE: 0.0016925755204790986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelkoo/Documents/GitHub/NBA-Analytics/nba-analytics/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NBA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
